{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistical Analysis of Current Commitments Dataset\n",
    "\n",
    "This notebook performs comprehensive statistical analysis on current criminal commitments data, including:\n",
    "\n",
    "- **Descriptive Statistics**: Overview of the dataset structure and basic metrics\n",
    "- **Categorical Analysis**: Distribution of offense types, relationships, and prison status\n",
    "- **Time-Based Analysis**: Temporal patterns in current offenses\n",
    "- **Enhancement Analysis**: Patterns in sentence enhancements\n",
    "- **Statistical Tests**: Chi-square, t-tests, correlation analysis, and Kruskal-Wallis tests\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from scipy.stats import chi2_contingency, ttest_ind, mannwhitneyu, kruskal\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style for visualizations\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "print(\"Libraries loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset\n",
    "\n",
    "The dataset should be placed in the `data/` folder at the project root."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "# Adjust the path if running from a different directory\n",
    "DATA_PATH = '../data/currentcommits.xlsx'\n",
    "\n",
    "print(\"Loading Current Commitments dataset...\")\n",
    "df = pd.read_excel(DATA_PATH)\n",
    "\n",
    "print(f\"\\nDataset loaded successfully!\")\n",
    "print(f\"Total records: {len(df):,}\")\n",
    "print(f\"Total columns: {len(df.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Descriptive Statistics\n",
    "\n",
    "Initial exploration of the dataset structure, data types, and basic statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset structure\n",
    "print(\"Dataset Info:\")\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview first few rows\n",
    "print(\"First few rows:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Column names\n",
    "print(\"Column names:\")\n",
    "print(df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Missing values analysis\n",
    "print(\"Missing values per column:\")\n",
    "missing = df.isnull().sum()\n",
    "missing_pct = (missing / len(df) * 100).round(2)\n",
    "missing_df = pd.DataFrame({'Missing Count': missing, 'Missing %': missing_pct})\n",
    "print(missing_df[missing_df['Missing Count'] > 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic statistics for numerical columns\n",
    "print(\"Basic statistics for numerical columns:\")\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Categorical Variable Analysis\n",
    "\n",
    "Examining the distribution of categorical variables in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define categorical columns to analyze\n",
    "categorical_cols = ['sentencing county', 'offense', 'offense description', \n",
    "                    'offense category', 'in-prison', 'relationship']\n",
    "\n",
    "for col in categorical_cols:\n",
    "    if col in df.columns:\n",
    "        print(f\"\\n{'='*50}\")\n",
    "        print(f\"{col.upper()}\")\n",
    "        print(f\"{'='*50}\")\n",
    "        print(f\"\\nTop 10 values:\")\n",
    "        print(df[col].value_counts().head(10))\n",
    "        print(f\"\\nUnique values: {df[col].nunique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Time-Based Analysis\n",
    "\n",
    "Analyzing temporal patterns in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert date columns to datetime\n",
    "date_cols = ['offense begin date', 'offense end date']\n",
    "for col in date_cols:\n",
    "    if col in df.columns:\n",
    "        df[col] = pd.to_datetime(df[col], errors='coerce')\n",
    "        print(f\"Converted '{col}' to datetime\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract year from offense begin date and analyze trends\n",
    "if 'offense begin date' in df.columns:\n",
    "    df['offense_year'] = df['offense begin date'].dt.year\n",
    "    \n",
    "    print(\"Current Offenses by Year (Last 20 years):\")\n",
    "    yearly_counts = df['offense_year'].value_counts().sort_index().tail(20)\n",
    "    print(yearly_counts)\n",
    "    \n",
    "    # Visualization\n",
    "    plt.figure(figsize=(14, 6))\n",
    "    yearly_counts.plot(kind='bar', color='steelblue', edgecolor='black')\n",
    "    plt.title('Number of Current Offenses by Year', fontsize=14)\n",
    "    plt.xlabel('Year')\n",
    "    plt.ylabel('Count')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate offense duration\n",
    "if 'offense begin date' in df.columns and 'offense end date' in df.columns:\n",
    "    df['offense_duration_days'] = (df['offense end date'] - df['offense begin date']).dt.days\n",
    "    \n",
    "    print(\"Offense Duration Statistics (in days):\")\n",
    "    print(df['offense_duration_days'].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Enhancement Analysis\n",
    "\n",
    "Analyzing sentence enhancements across records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count enhancements per record\n",
    "enhancement_cols = [f'off_enh{i}' for i in range(1, 12)]\n",
    "existing_enh_cols = [col for col in enhancement_cols if col in df.columns]\n",
    "\n",
    "if existing_enh_cols:\n",
    "    df['total_enhancements'] = df[existing_enh_cols].notna().sum(axis=1)\n",
    "    \n",
    "    print(\"Enhancement Statistics:\")\n",
    "    print(f\"\\nDistribution of enhancement counts:\")\n",
    "    print(df['total_enhancements'].value_counts().sort_index())\n",
    "    print(f\"\\nAverage enhancements per record: {df['total_enhancements'].mean():.2f}\")\n",
    "    print(f\"Median enhancements per record: {df['total_enhancements'].median():.2f}\")\n",
    "    print(f\"Max enhancements on single record: {df['total_enhancements'].max():.0f}\")\n",
    "    \n",
    "    # Visualization\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    df['total_enhancements'].value_counts().sort_index().plot(kind='bar', color='darkred', edgecolor='black')\n",
    "    plt.title('Distribution of Enhancements per Record', fontsize=14)\n",
    "    plt.xlabel('Number of Enhancements')\n",
    "    plt.ylabel('Count')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Most common enhancement types\n",
    "print(\"Most Common Enhancement Types:\")\n",
    "for i in range(1, 4):  # Top 3 enhancement columns\n",
    "    col = f'off_enh{i}'\n",
    "    if col in df.columns:\n",
    "        print(f\"\\n{col.upper()}:\")\n",
    "        print(df[col].value_counts().head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Chi-Square Tests\n",
    "\n",
    "Testing for associations between categorical variables using Chi-square tests of independence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 1: Offense Category vs Relationship Type\n",
    "if 'offense category' in df.columns and 'relationship' in df.columns:\n",
    "    print(\"Chi-Square Test: Offense Category vs Relationship Type\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    contingency_table = pd.crosstab(df['offense category'], df['relationship'])\n",
    "    chi2, p_value, dof, expected = chi2_contingency(contingency_table)\n",
    "    \n",
    "    print(f\"\\nChi-square statistic: {chi2:.4f}\")\n",
    "    print(f\"P-value: {p_value:.4e}\")\n",
    "    print(f\"Degrees of freedom: {dof}\")\n",
    "    print(f\"\\nResult: {'Statistically Significant' if p_value < 0.05 else 'Not Statistically Significant'} at α=0.05\")\n",
    "    \n",
    "    print(\"\\nContingency Table:\")\n",
    "    display(contingency_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 2: Offense Category vs In Prison Status\n",
    "if 'offense category' in df.columns and 'in-prison' in df.columns:\n",
    "    print(\"Chi-Square Test: Offense Category vs In-Prison Status\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    df_filtered = df[df['in-prison'].notna() & (df['in-prison'] != '')]\n",
    "    \n",
    "    if len(df_filtered) > 0:\n",
    "        contingency_table2 = pd.crosstab(df_filtered['offense category'], df_filtered['in-prison'])\n",
    "        chi2_2, p_value_2, dof_2, expected_2 = chi2_contingency(contingency_table2)\n",
    "        \n",
    "        print(f\"\\nChi-square statistic: {chi2_2:.4f}\")\n",
    "        print(f\"P-value: {p_value_2:.4e}\")\n",
    "        print(f\"Degrees of freedom: {dof_2}\")\n",
    "        print(f\"\\nResult: {'Statistically Significant' if p_value_2 < 0.05 else 'Not Statistically Significant'} at α=0.05\")\n",
    "        \n",
    "        print(\"\\nContingency Table:\")\n",
    "        display(contingency_table2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 3: Has Enhancements vs Offense Category\n",
    "if 'total_enhancements' in df.columns:\n",
    "    print(\"Chi-Square Test: Has Enhancements vs Offense Category\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    df['has_enhancements'] = df['total_enhancements'] > 0\n",
    "    contingency_table3 = pd.crosstab(df['offense category'], df['has_enhancements'])\n",
    "    chi2_3, p_value_3, dof_3, expected_3 = chi2_contingency(contingency_table3)\n",
    "    \n",
    "    print(f\"\\nChi-square statistic: {chi2_3:.4f}\")\n",
    "    print(f\"P-value: {p_value_3:.4e}\")\n",
    "    print(f\"Degrees of freedom: {dof_3}\")\n",
    "    print(f\"\\nResult: {'Statistically Significant' if p_value_3 < 0.05 else 'Not Statistically Significant'} at α=0.05\")\n",
    "    \n",
    "    print(\"\\nContingency Table:\")\n",
    "    display(contingency_table3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. T-Tests\n",
    "\n",
    "Comparing mean number of enhancements between different offense categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare number of enhancements between different offense categories\n",
    "if 'total_enhancements' in df.columns and 'offense category' in df.columns:\n",
    "    print(\"T-Test: Enhancements - Drug Crimes vs Property Crimes\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    drug_crimes = df[df['offense category'] == 'Drug Crimes']['total_enhancements'].dropna()\n",
    "    property_crimes = df[df['offense category'] == 'Property Crimes']['total_enhancements'].dropna()\n",
    "    \n",
    "    if len(drug_crimes) > 0 and len(property_crimes) > 0:\n",
    "        t_stat, p_value_t = ttest_ind(drug_crimes, property_crimes)\n",
    "        \n",
    "        print(f\"\\nDrug Crimes:\")\n",
    "        print(f\"  - Sample size: {len(drug_crimes):,}\")\n",
    "        print(f\"  - Mean enhancements: {drug_crimes.mean():.2f}\")\n",
    "        print(f\"  - Std deviation: {drug_crimes.std():.2f}\")\n",
    "        \n",
    "        print(f\"\\nProperty Crimes:\")\n",
    "        print(f\"  - Sample size: {len(property_crimes):,}\")\n",
    "        print(f\"  - Mean enhancements: {property_crimes.mean():.2f}\")\n",
    "        print(f\"  - Std deviation: {property_crimes.std():.2f}\")\n",
    "        \n",
    "        print(f\"\\nT-statistic: {t_stat:.4f}\")\n",
    "        print(f\"P-value: {p_value_t:.4e}\")\n",
    "        print(f\"\\nResult: {'Statistically Significant difference' if p_value_t < 0.05 else 'No statistically significant difference'} at α=0.05\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# T-Test: Crimes Against Persons vs Property Crimes\n",
    "if 'total_enhancements' in df.columns and 'offense category' in df.columns:\n",
    "    print(\"T-Test: Enhancements - Crimes Against Persons vs Property Crimes\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    person_crimes = df[df['offense category'] == 'Crimes Against Persons']['total_enhancements'].dropna()\n",
    "    property_crimes = df[df['offense category'] == 'Property Crimes']['total_enhancements'].dropna()\n",
    "    \n",
    "    if len(person_crimes) > 0 and len(property_crimes) > 0:\n",
    "        t_stat2, p_value_t2 = ttest_ind(person_crimes, property_crimes)\n",
    "        \n",
    "        print(f\"\\nCrimes Against Persons:\")\n",
    "        print(f\"  - Sample size: {len(person_crimes):,}\")\n",
    "        print(f\"  - Mean enhancements: {person_crimes.mean():.2f}\")\n",
    "        print(f\"  - Std deviation: {person_crimes.std():.2f}\")\n",
    "        \n",
    "        print(f\"\\nProperty Crimes:\")\n",
    "        print(f\"  - Sample size: {len(property_crimes):,}\")\n",
    "        print(f\"  - Mean enhancements: {property_crimes.mean():.2f}\")\n",
    "        print(f\"  - Std deviation: {property_crimes.std():.2f}\")\n",
    "        \n",
    "        print(f\"\\nT-statistic: {t_stat2:.4f}\")\n",
    "        print(f\"P-value: {p_value_t2:.4e}\")\n",
    "        print(f\"\\nResult: {'Statistically Significant difference' if p_value_t2 < 0.05 else 'No statistically significant difference'} at α=0.05\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 7. Correlation Analysis\n",
    "\n",
    "Examining relationships between numerical variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count current offenses per individual\n",
    "if 'cdcno' in df.columns:\n",
    "    current_counts = df.groupby('cdcno').size().reset_index(name='current_offense_count')\n",
    "    \n",
    "    print(\"Current Offense Count Statistics:\")\n",
    "    print(current_counts['current_offense_count'].describe())\n",
    "    \n",
    "    # Merge back to main dataframe\n",
    "    df = df.merge(current_counts, on='cdcno', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation between current offenses and enhancements\n",
    "if 'current_offense_count' in df.columns and 'total_enhancements' in df.columns:\n",
    "    print(\"Correlation Analysis: Current Offenses vs Enhancements\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Pearson correlation\n",
    "    correlation = df[['current_offense_count', 'total_enhancements']].corr()\n",
    "    print(\"\\nPearson Correlation Matrix:\")\n",
    "    print(correlation)\n",
    "    \n",
    "    # Spearman correlation (non-parametric)\n",
    "    df_corr = df[['current_offense_count', 'total_enhancements']].dropna()\n",
    "    if len(df_corr) > 0:\n",
    "        spearman_corr, spearman_p = stats.spearmanr(\n",
    "            df_corr['current_offense_count'], \n",
    "            df_corr['total_enhancements']\n",
    "        )\n",
    "        \n",
    "        print(f\"\\nSpearman Correlation: {spearman_corr:.4f}\")\n",
    "        print(f\"P-value: {spearman_p:.4e}\")\n",
    "        print(f\"\\nResult: {'Statistically Significant correlation' if spearman_p < 0.05 else 'No statistically significant correlation'} at α=0.05\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 8. Kruskal-Wallis Test\n",
    "\n",
    "Non-parametric test to compare enhancements across multiple offense categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'total_enhancements' in df.columns and 'offense category' in df.columns:\n",
    "    print(\"Kruskal-Wallis Test: Enhancements across Offense Categories\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Get groups\n",
    "    groups = []\n",
    "    group_names = []\n",
    "    categories = df['offense category'].dropna().unique()\n",
    "    \n",
    "    for cat in categories:\n",
    "        group_data = df[df['offense category'] == cat]['total_enhancements'].dropna()\n",
    "        if len(group_data) > 0:\n",
    "            groups.append(group_data)\n",
    "            group_names.append(cat)\n",
    "    \n",
    "    if len(groups) > 1:\n",
    "        h_stat, p_value_kw = kruskal(*groups)\n",
    "        \n",
    "        print(f\"\\nNumber of groups: {len(groups)}\")\n",
    "        print(f\"H-statistic: {h_stat:.4f}\")\n",
    "        print(f\"P-value: {p_value_kw:.4e}\")\n",
    "        print(f\"\\nResult: {'Statistically Significant difference' if p_value_kw < 0.05 else 'No statistically significant difference'} at α=0.05\")\n",
    "        \n",
    "        # Show mean enhancements by category\n",
    "        print(\"\\nMean Enhancements by Offense Category:\")\n",
    "        for cat in categories:\n",
    "            cat_data = df[df['offense category'] == cat]['total_enhancements']\n",
    "            print(f\"  {cat}: {cat_data.mean():.2f} (n={len(cat_data):,})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 9. Distribution Analysis\n",
    "\n",
    "Visualizing the distribution of key categorical variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'offense category' in df.columns:\n",
    "    print(\"Offense Category Distribution\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    offense_dist = df['offense category'].value_counts()\n",
    "    offense_pct = (offense_dist / len(df) * 100).round(2)\n",
    "    \n",
    "    dist_df = pd.DataFrame({\n",
    "        'Count': offense_dist,\n",
    "        'Percentage': offense_pct\n",
    "    })\n",
    "    print(dist_df)\n",
    "    \n",
    "    # Visualization\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    offense_dist.plot(kind='barh', color='steelblue', edgecolor='black')\n",
    "    plt.title('Distribution of Offense Categories', fontsize=14)\n",
    "    plt.xlabel('Count')\n",
    "    plt.ylabel('Offense Category')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'relationship' in df.columns:\n",
    "    print(\"Relationship Type Distribution\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    relationship_dist = df['relationship'].value_counts()\n",
    "    relationship_pct = (relationship_dist / len(df) * 100).round(2)\n",
    "    \n",
    "    dist_df = pd.DataFrame({\n",
    "        'Count': relationship_dist,\n",
    "        'Percentage': relationship_pct\n",
    "    })\n",
    "    print(dist_df)\n",
    "    \n",
    "    # Visualization\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    relationship_dist.plot(kind='bar', color='coral', edgecolor='black')\n",
    "    plt.title('Distribution of Relationship Types', fontsize=14)\n",
    "    plt.xlabel('Relationship Type')\n",
    "    plt.ylabel('Count')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 10. Current Commitment Patterns\n",
    "\n",
    "Analyzing patterns among currently committed individuals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'cdcno' in df.columns:\n",
    "    print(\"Current Commitment Patterns\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    commitment_data = df.groupby('cdcno').agg({\n",
    "        'offense begin date': 'count',\n",
    "        'total_enhancements': 'mean',\n",
    "        'offense category': lambda x: x.mode()[0] if len(x.mode()) > 0 else None\n",
    "    }).reset_index()\n",
    "    commitment_data.columns = ['cdcno', 'total_current_offenses', 'avg_enhancements', 'most_common_offense']\n",
    "    \n",
    "    print(f\"\\nTotal unique individuals: {len(commitment_data):,}\")\n",
    "    print(f\"Average current offenses per person: {commitment_data['total_current_offenses'].mean():.2f}\")\n",
    "    print(f\"Median current offenses per person: {commitment_data['total_current_offenses'].median():.2f}\")\n",
    "    print(f\"Average enhancements per person: {commitment_data['avg_enhancements'].mean():.2f}\")\n",
    "    \n",
    "    print(\"\\nDistribution of current offenses per person:\")\n",
    "    offense_per_person = commitment_data['total_current_offenses'].value_counts().sort_index().head(10)\n",
    "    print(offense_per_person)\n",
    "    \n",
    "    # Visualization\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    offense_per_person.plot(kind='bar', color='darkgreen', edgecolor='black')\n",
    "    plt.title('Distribution of Current Offenses per Individual', fontsize=14)\n",
    "    plt.xlabel('Number of Offenses')\n",
    "    plt.ylabel('Number of Individuals')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 11. Summary Report\n",
    "\n",
    "Consolidated summary of key findings from the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"SUMMARY REPORT\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Create summary dictionary\n",
    "summary = {\n",
    "    'Total Records': f\"{len(df):,}\",\n",
    "    'Unique Individuals': f\"{df['cdcno'].nunique():,}\" if 'cdcno' in df.columns else 'N/A',\n",
    "    'Date Range': f\"{df['offense begin date'].min().strftime('%Y-%m-%d')} to {df['offense begin date'].max().strftime('%Y-%m-%d')}\" if 'offense begin date' in df.columns and df['offense begin date'].notna().any() else 'N/A',\n",
    "    'Most Common Offense Category': df['offense category'].mode()[0] if 'offense category' in df.columns else 'N/A',\n",
    "    'Average Enhancements per Record': f\"{df['total_enhancements'].mean():.2f}\" if 'total_enhancements' in df.columns else 'N/A',\n",
    "    'Records with Enhancements': f\"{(df['has_enhancements'].sum() / len(df) * 100):.2f}%\" if 'has_enhancements' in df.columns else 'N/A'\n",
    "}\n",
    "\n",
    "for key, value in summary.items():\n",
    "    print(f\"{key}: {value}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ANALYSIS COMPLETE\")\n",
    "print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
